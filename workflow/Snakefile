#!/usr/bin/env python3


include: "rules/common.smk"


# So far I have only implemented filtering the data on project, context and
# datatype. Haven't decided if metadata mapping should be a second run through
# the filtered samples.
rule filter_datasets:
    input:
        json="resources/datasets.jsonl.gz",
        data_mapping_config="config/data_mapping_config.json",
    output:
        filtered_datasets="results/filtered_datasets.jsonl.gz",
        decision_log="results/decision_log.csv",
    log:
        "logs/filter_datasets.log",
    container:
        get_container("ncbi-datasets-pylib")  # has jsonlines
    script:
        "scripts/filter_datasets.py"


rule parse_bpa_json:
    input:
        json="resources/datasets.jsonl.gz",
    output:
        sample_id_dict="results/sample_id_dict.jsonl.gz",
        bioplatforms_id_dict="results/bioplatforms_id_dict.jsonl.gz",
        equivalent_samples="results/equivalent_samples.jsonl.gz",
    log:
        "logs/parse_bpa_json.log",
    container:
        get_container("ncbi-datasets-pylib")  # has jsonlines
    script:
        "scripts/parse_bpa_json.py"


rule dump_bpa:
    params:
        apikey=get_apikey(),
        url=config["bpa_url"],
    output:
        "resources/datasets.jsonl.gz",
    log:
        "logs/dump_bpa.log",
    # todo:
    # container: get_container("ncbi-datasets-pylib")
    shell:
        "ckanapi search datasets "
        " -a {params.apikey} "
        "include_private=true "
        "-O {output} "
        "-z "
        "-r {params.url} "
        "&> {log}"
